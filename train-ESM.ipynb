{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESM-1nv Training with BioNeMo on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2024 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "SPDX-License-Identifier: MIT-0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Create clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import sagemaker\n",
    "from time import strftime\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "sagemaker_session = sagemaker.session.Session(boto_session)\n",
    "REGION_NAME = sagemaker_session.boto_region_name\n",
    "S3_BUCKET = sagemaker_session.default_bucket()\n",
    "S3_PREFIX = \"bionemo-training\"\n",
    "S3_FOLDER = sagemaker.s3.s3_path_join(\"s3://\", S3_BUCKET, S3_PREFIX)\n",
    "print(f\"S3 uri is {S3_FOLDER}\")\n",
    "\n",
    "EXPERIMENT_NAME = \"bionemo-training-\" + strftime(\"%Y-%m-%d\")\n",
    "\n",
    "SAGEMAKER_EXECUTION_ROLE = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "print(f\"Assumed SageMaker role is {SAGEMAKER_EXECUTION_ROLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.2. Build BioNeMo-SageMaker Container Image\n",
    "\n",
    "If you don't already have access to the BioNeMo-SageMaker container image, run the following cell to build and deploy it to your AWS account. Take note of the image URI - you'll use it for the processing and training steps below.\n",
    "\n",
    "Here is an example shell script you can use in your environment (including SageMaker Notebook Instances) to build the container.\n",
    "\n",
    "Once you have built and pushed the container, we strongly recommend using [ECR image scanning](https://docs.aws.amazon.com/AmazonECR/latest/userguide/image-scanning.html) to ensure that it meets your security requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=bionemo-training\n",
    "\n",
    "pushd container/training\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}\n",
    "\n",
    "popd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Query UniProt for human amino acid sequences between 100 and 1000 residues in length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "query_url = \"https://rest.uniprot.org/uniprotkb/stream?query=organism_id:9606+AND+reviewed=True+AND+length=[100+TO+1000]&format=tsv&compressed=true&fields=accession,sequence\"\n",
    "uniprot_request = requests.get(query_url)\n",
    "bio = BytesIO(uniprot_request.content)\n",
    "\n",
    "df = pd.read_csv(bio, compression=\"gzip\", sep=\"\\t\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Split Data and Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = df.sample(n=9600, random_state=42)\n",
    "val_test = df.drop(train.index)\n",
    "val = val_test.sample(n=960, random_state=42)\n",
    "test = val_test.drop(val.index).sample(n=960, random_state=42)\n",
    "del val_test\n",
    "\n",
    "print(f\"Training data size: {train.shape}\")\n",
    "print(f\"Validation data size: {val.shape}\")\n",
    "print(f\"Test data size: {test.shape}\")\n",
    "\n",
    "for dir in [\"train\", \"val\", \"test\"]:\n",
    "    if not os.path.exists(os.path.join(\"data\", dir)):\n",
    "        os.makedirs(os.path.join(\"data\", dir))\n",
    "\n",
    "train.to_csv(os.path.join(\"data\", \"train\", \"x000.csv\"), index=False)\n",
    "val.to_csv(os.path.join(\"data\", \"val\", \"x001.csv\"), index=False)\n",
    "test.to_csv(os.path.join(\"data\", \"test\", \"x002.csv\"), index=False)\n",
    "\n",
    "DATA_PREFIX = os.path.join(S3_PREFIX, \"data\")\n",
    "DATA_URI = sagemaker_session.upload_data(\n",
    "    path=\"data\", bucket=S3_BUCKET, key_prefix=DATA_PREFIX\n",
    ")\n",
    "print(f\"Sequence data available at {DATA_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Configure NVIDIA NGC API Credentiatls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you create a BioNeMo training job, follow these steps to generate some NGC API credentials and store them in AWS Secrets Manager. \n",
    "\n",
    "1. Sign-in or create a new account at NVIDIA [NGC](https://ngc.nvidia.com/signin).\n",
    "2. Select your name in the top-right corner of the screen and then \"Setup\"\n",
    "\n",
    "![Select Setup from the top-right menup](img/1-setup.png)\n",
    "\n",
    "3. Select \"Generate API Key\".\n",
    "\n",
    "![Select Generate API Key](img/2-api-key.png)\n",
    "\n",
    "4. Select the green \"+ Generate API Key\" button and confirm.\n",
    "\n",
    "![Select green Generate API Key button ](img/3-generate.png)\n",
    "\n",
    "5. Copy the API key - this is the last time you can retrieve it!\n",
    "\n",
    "6. Before you leave the NVIDIA NGC site, also take note of your organization ID listed under your name in the top-right corner of the screen. You'll need this, plus your API key, to download BioNeMo artifacts.\n",
    "\n",
    "7. Navigate to the AWS Console and then to AWS Secrets Manager.\n",
    "\n",
    "![Navigate to AWS Secrets Manager](img/4-sm.png)\n",
    "\n",
    "8. Select \"Store a new secret\".\n",
    "9. Under \"Secret type\" select \"Other type of secret\"\n",
    "\n",
    "![Select other type of secret](img/5-secret-type.png)\n",
    "\n",
    "10. Under \"Key/value\" pairs, add a key named \"NGC_CLI_API_KEY\" with a value of your NGC API key. Add another key named \"NGC_CLI_ORG\" with a value of your NGC organization. Select Next.\n",
    "\n",
    "11. Under \"Configure secret - Secret name and description\", name your secret \"NVIDIA_NGC_CREDS\" and select Next. You'll use this secret name when submitting BioNeMo jobs to SageMaker.\n",
    "\n",
    "12. Select the remaining default options to create your secret.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Submit ESM-1nv Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# Replace this with your ECR repository URI from above\n",
    "BIONEMO_IMAGE_URI = (\n",
    "    \"<ACCOUNT ID>.dkr.ecr.<REGION>.amazonaws.com/bionemo-training:latest\"\n",
    ")\n",
    "\n",
    "bionemo_estimator = PyTorch(\n",
    "    base_job_name=\"bionemo-training\",\n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}},\n",
    "    entry_point=\"train.py\",\n",
    "    hyperparameters={\n",
    "        \"config-name\": \"esm1nv-training\",  # This is  the name of your config file, without the extension\n",
    "        \"model-name\": \"esm1nv\",  # If you don't provide this as a hyperparameter, it will be inferred from the name field in the config file\n",
    "        \"download-pretrained-weights\": True,  # Required to fine-tune from pretrained weights. Set to False for pretraining.\n",
    "        \"ngc-cli-secret-name\": \"NVIDIA_NGC_CREDS\",  # Replace this if you used a different name above.\n",
    "    },\n",
    "    image_uri=BIONEMO_IMAGE_URI,\n",
    "    instance_count=2,  # Update this value for multi-node training\n",
    "    instance_type=\"ml.g5.2xlarge\",  # Update this value for other instance types\n",
    "    keep_alive_period_in_seconds=3600,\n",
    "    output_path=os.path.join(S3_FOLDER, \"model\"),\n",
    "    role=SAGEMAKER_EXECUTION_ROLE,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    source_dir=\"src\",\n",
    ")\n",
    "\n",
    "with Run(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    bionemo_estimator.fit(\n",
    "        inputs={\n",
    "            \"train\": os.path.join(DATA_URI, \"train\"),\n",
    "            \"val\": os.path.join(DATA_URI, \"val\"),\n",
    "        },\n",
    "        wait=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
